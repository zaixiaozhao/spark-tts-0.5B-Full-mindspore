{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1.首先需要进行数据转换，使用怕predata.py代码。该代码是通过Spark-TTS的模型进行数据转换的。注意需要从huggface下载对应模型，并保存在SparkTTSmain对应的目录下。\n",
    "# 2.将第一步转换的data.jsonl数据转换为mindrecord格式，使用datatomind.py代码。该代码形成的yaml文件是属于lora的，需要将lora给注释，否则训练时loss值不会降低，因为lora会冻结，而本项目使用的模型的词表在原先的词表基础上有添加，因此采取全量微调方式\n",
    "# 3.模型转换，需要将huggface的Spark-TTS模型转换成ckpt模型，使用convert.py代码。该代码会生成一个mindspore_model.ckpt的模型，该模型是Spark-TTS的模型，但是训练时需要使用mindspore的模型，因此需要转换。接着还需对转换过后的mindspore_model.ckpt模型进行一些层的重命名，因为需要与mindspre底层的层名进行对应否则权重不会加载进去。最后生成的模型是mindspore_model_final.ckpt。注意：第二步的yaml文件模型路径需要与第三步的模型路径保持一致。\n",
    "# 4.训练：拉取mindformers 代码：git clone https://gitee.com/mindspore/mindformers.git，但是需要注意的是这个版本太新，有些算子不支持，需要降低版本：cd mindformers && git checkout v1.7.0      此步骤建议在根目录下执行\n",
    "# 5.推理：使用predicate.py代码。需要配置yaml_path，ckpt_path，TOKENIZER_DIR。ckpt_path是训练好的模型，yaml_path是训练的yaml文件，TOKENIZER_DIR是分词器路径目录（需要下载，是Spark-TTS-0.5B模型）。\n",
    "# 6.编码：运行decodec.py\n",
    "# 本项目需要两个虚拟环境，一个用于mindspore的训练，一个是编码与解码bicodec。bicodec的环境执行pip install requirements1.txt\n",
    "# mindspore的训练环境需要按照requirements2.txt安装\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
