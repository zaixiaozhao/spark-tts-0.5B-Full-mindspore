import torch
import soundfile as sf
import json
import os
import sys
import re
from safetensors.torch import load_file  # éœ€è¦ pip install safetensors

# ================= é…ç½®åŒº =================
# 1. Spark-TTS æºç è·¯å¾„ (å¿…é¡»è®¾ç½®ï¼Œç”¨äºå¯¼å…¥ BiCodec ç±»)
SPARK_TTS_CODE_DIR = "/root/Spark-TTS-main"

# 2. æ¨¡å‹æ–‡ä»¶å¤¹è·¯å¾„ (è¯¥ç›®å½•ä¸‹å¿…é¡»æœ‰ model.safetensors å’Œ config.json)
BICODEC_DIR = "./Bicodec"
MODEL_FILENAME = "model.safetensors"  # ä½ çš„æ–‡ä»¶å

# 3. Token æ–‡ä»¶
TOKEN_FILE = "generated_tokens.txt"
# =========================================

# å¯¼å…¥ Spark-TTS æºç 
sys.path.append(SPARK_TTS_CODE_DIR)
try:
    from spark_tts.model.audio_codec import BiCodec

    print(">>> æˆåŠŸå¯¼å…¥ BiCodec ç±»")
except ImportError:
    print(f"âŒ æ— æ³•å¯¼å…¥ Spark-TTS ä»£ç ï¼Œè¯·æ£€æŸ¥ SPARK_TTS_CODE_DIR: {SPARK_TTS_CODE_DIR}")
    exit()


def extract_ids(text):
    g_ids = [int(x) for x in re.findall(r'\|bicodec_global_(\d+)\|', text)]
    s_ids = [int(x) for x in re.findall(r'\|bicodec_semantic_(\d+)\|', text)]
    return g_ids, s_ids


def main():
    device = "cpu"
    config_path = os.path.join(BICODEC_DIR, "config.json")
    ckpt_path = os.path.join(BICODEC_DIR, MODEL_FILENAME)

    # 1. æ£€æŸ¥æ–‡ä»¶
    if not os.path.exists(config_path):
        print(f"âŒ é”™è¯¯ï¼šæ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ {config_path}")
        print("Safetensors æ ¼å¼åªå­˜äº†å‚æ•°ï¼Œç”±äºä¸çŸ¥é“æ¨¡å‹ç»“æ„ï¼Œå¿…é¡»è¦æœ‰ config.json æ‰èƒ½åˆå§‹åŒ–æ¨¡å‹ï¼")
        return

    # 2. åˆå§‹åŒ–æ¨¡å‹ç»“æ„
    print(">>> æ­£åœ¨åˆå§‹åŒ– BiCodec æ¨¡å‹ç»“æ„...")
    with open(config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)

    # å®ä¾‹åŒ–æ¨¡å‹ (æ ¹æ® config)
    model = BiCodec(**config)

    # 3. åŠ è½½ Safetensors æƒé‡
    print(f">>> æ­£åœ¨åŠ è½½æƒé‡: {ckpt_path}")
    try:
        state_dict = load_file(ckpt_path)  # ä½¿ç”¨ safetensors åº“åŠ è½½
        model.load_state_dict(state_dict)  # æ³¨å…¥æƒé‡
        model.to(device)
        model.eval()
        print(">>> âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼")
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥: {e}")
        return

    # 4. è¯»å– Token å¹¶è§£ç 
    if not os.path.exists(TOKEN_FILE):
        print(f"âŒ æ‰¾ä¸åˆ° {TOKEN_FILE}")
        return

    with open(TOKEN_FILE, 'r', encoding='utf-8') as f:
        text = f.read()

    g_ids, s_ids = extract_ids(text)
    print(f"æå–åˆ°: Global={len(g_ids)}, Semantic={len(s_ids)}")

    if not s_ids:
        print("âŒ æœªæå–åˆ° Semantic Tokensï¼Œæ— æ³•ç”Ÿæˆã€‚")
        return

    print(">>> æ­£åœ¨è§£ç éŸ³é¢‘...")
    with torch.no_grad():
        # æ„é€ è¾“å…¥å¼ é‡
        semantic_tensor = torch.tensor([s_ids], dtype=torch.long, device=device)
        global_tensor = torch.tensor([g_ids], dtype=torch.long, device=device)

        # è§£ç 
        wav = model.decode(semantic_tensor, global_tensor)

    save_path = "final_output.wav"
    sf.write(save_path, wav.squeeze().numpy(), 24000)
    print(f"\nğŸ‰ æ­å–œï¼éŸ³é¢‘å·²ç”Ÿæˆ: {save_path}")
    print("å¿«ä¸‹è½½ä¸‹æ¥å¬å¬å§ï¼")


if __name__ == "__main__":
    main()